{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55c18a0-3922-463b-be02-d67316e9d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "anyio                     4.4.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "astunparse                1.6.3\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "certifi                   2024.7.4\n",
      "cffi                      1.17.0\n",
      "charset-normalizer        3.3.2\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.2.1\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.5\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.15.4\n",
      "flatbuffers               24.3.25\n",
      "fonttools                 4.53.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2024.6.1\n",
      "gast                      0.6.0\n",
      "google-pasta              0.2.0\n",
      "grpcio                    1.65.5\n",
      "h11                       0.14.0\n",
      "h5py                      3.11.0\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "huggingface-hub           0.24.6\n",
      "idna                      3.7\n",
      "intel-openmp              2021.4.0\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.26.0\n",
      "ipywidgets                8.1.3\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.2\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.11\n",
      "keras                     3.5.0\n",
      "kiwisolver                1.4.5\n",
      "lab                       8.2\n",
      "libclang                  18.1.1\n",
      "Markdown                  3.7\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.2\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.2\n",
      "mkl                       2021.4.0\n",
      "ml-dtypes                 0.4.0\n",
      "mpmath                    1.3.0\n",
      "namex                     0.0.8\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.3\n",
      "notebook                  7.2.1\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "opt-einsum                3.3.0\n",
      "optree                    0.12.1\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pillow                    10.4.0\n",
      "pip                       24.2\n",
      "platformdirs              4.2.2\n",
      "prometheus_client         0.20.0\n",
      "prompt_toolkit            3.0.47\n",
      "protobuf                  4.25.4\n",
      "psutil                    6.0.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "pyparsing                 3.1.2\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.13\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.1.1\n",
      "qtconsole                 5.5.2\n",
      "QtPy                      2.4.1\n",
      "referencing               0.35.1\n",
      "regex                     2024.7.24\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.7.1\n",
      "rpds-py                   0.20.0\n",
      "safetensors               0.4.4\n",
      "Send2Trash                1.8.3\n",
      "sentencepiece             0.2.0\n",
      "setuptools                73.0.1\n",
      "simplejson                3.19.3\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.2\n",
      "tbb                       2021.13.1\n",
      "tensorboard               2.17.1\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorflow                2.17.0\n",
      "tensorflow-intel          2.17.0\n",
      "termcolor                 2.4.0\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.3.0\n",
      "tokenizers                0.19.1\n",
      "torch                     2.3.1+cu118\n",
      "torchaudio                2.3.1+cu118\n",
      "torchvision               0.18.1+cu118\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.66.5\n",
      "traitlets                 5.14.3\n",
      "transformers              4.44.1\n",
      "txt2tags                  3.9\n",
      "types-python-dateutil     2.9.0.20240821\n",
      "typing_extensions         4.12.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.2\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.8.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.3\n",
      "wheel                     0.44.0\n",
      "widgetsnbextension        4.0.11\n",
      "wrapt                     1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc575c2-9031-4f74-b49e-5ece1d3e5cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\kevin\\OneDrive\\Desktop\\fyp\\fypEnv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\OneDrive\\Desktop\\fyp\\fypEnv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55668a67-bf5a-4fd9-bf7f-915f40a2194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25dcfe22-54a0-4afd-bbf9-5b1063d78c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1494,  339,  259,  262, 2978, 7461,  260,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = \"This is a test text.\"\n",
    "token_ids = tokenizer.encode(input_sentence, return_tensors = \"pt\").cuda()\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad04e2ce-ccb3-46a1-a722-86d5505a8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\OneDrive\\Desktop\\fyp\\fypEnv\\Lib\\site-packages\\transformers\\generation\\utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0, 250099,      1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_out = model.generate(token_ids)\n",
    "print(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdcb6e2-5f9b-448a-b1e1-6cd768562d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypEnvJupyter",
   "language": "python",
   "name": "fypenvjupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
