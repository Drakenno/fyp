{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55c18a0-3922-463b-be02-d67316e9d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "absl-py                   2.1.0\n",
      "aiohappyeyeballs          2.4.0\n",
      "aiohttp                   3.10.5\n",
      "aiosignal                 1.3.1\n",
      "anyio                     4.4.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "astunparse                1.6.3\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.1.0\n",
      "certifi                   2024.7.4\n",
      "cffi                      1.17.0\n",
      "charset-normalizer        3.3.2\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.2\n",
      "contourpy                 1.2.1\n",
      "cycler                    0.12.1\n",
      "datasets                  2.21.0\n",
      "debugpy                   1.8.5\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "dill                      0.3.8\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.20.0\n",
      "filelock                  3.15.4\n",
      "flatbuffers               24.3.25\n",
      "fonttools                 4.53.1\n",
      "fqdn                      1.5.1\n",
      "frozenlist                1.4.1\n",
      "fsspec                    2024.6.1\n",
      "gast                      0.6.0\n",
      "google-pasta              0.2.0\n",
      "grpcio                    1.65.5\n",
      "h11                       0.14.0\n",
      "h5py                      3.11.0\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "huggingface-hub           0.24.6\n",
      "idna                      3.7\n",
      "intel-openmp              2021.4.0\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.26.0\n",
      "ipywidgets                8.1.3\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter                   1.0.0\n",
      "jupyter_client            8.6.2\n",
      "jupyter-console           6.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.11\n",
      "keras                     3.5.0\n",
      "kiwisolver                1.4.5\n",
      "lab                       8.2\n",
      "libclang                  18.1.1\n",
      "Markdown                  3.7\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.2\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.0.2\n",
      "mkl                       2021.4.0\n",
      "ml-dtypes                 0.4.0\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.0.5\n",
      "multiprocess              0.70.16\n",
      "namex                     0.0.8\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.3\n",
      "notebook                  7.2.1\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "opt-einsum                3.3.0\n",
      "optree                    0.12.1\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "pandas                    2.2.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pillow                    10.4.0\n",
      "pip                       24.2\n",
      "platformdirs              4.2.2\n",
      "prometheus_client         0.20.0\n",
      "prompt_toolkit            3.0.47\n",
      "protobuf                  4.25.4\n",
      "psutil                    6.0.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   17.0.0\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "pyparsing                 3.1.2\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.13\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.1.1\n",
      "qtconsole                 5.5.2\n",
      "QtPy                      2.4.1\n",
      "referencing               0.35.1\n",
      "regex                     2024.7.24\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      13.7.1\n",
      "rpds-py                   0.20.0\n",
      "safetensors               0.4.4\n",
      "Send2Trash                1.8.3\n",
      "sentencepiece             0.2.0\n",
      "setuptools                73.0.1\n",
      "simplejson                3.19.3\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.2\n",
      "tbb                       2021.13.1\n",
      "tensorboard               2.17.1\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorflow                2.17.0\n",
      "tensorflow-intel          2.17.0\n",
      "termcolor                 2.4.0\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.3.0\n",
      "tokenizers                0.19.1\n",
      "torch                     2.3.1+cu118\n",
      "torchaudio                2.3.1+cu118\n",
      "torchvision               0.18.1+cu118\n",
      "tornado                   6.4.1\n",
      "tqdm                      4.66.5\n",
      "traitlets                 5.14.3\n",
      "transformers              4.44.1\n",
      "txt2tags                  3.9\n",
      "types-python-dateutil     2.9.0.20240821\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2024.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.2\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.8.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.0.3\n",
      "wheel                     0.44.0\n",
      "widgetsnbextension        4.0.11\n",
      "wrapt                     1.16.0\n",
      "xxhash                    3.5.0\n",
      "yarl                      1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc575c2-9031-4f74-b49e-5ece1d3e5cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Users\\kevin\\OneDrive\\Desktop\\fyp\\fypEnv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\kevin\\OneDrive\\Desktop\\fyp\\fypEnv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55668a67-bf5a-4fd9-bf7f-915f40a2194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25dcfe22-54a0-4afd-bbf9-5b1063d78c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1494,  339,  259,  262, 2978, 7461,  260,    1]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = \"This is a test text.\"\n",
    "token_ids = tokenizer.encode(input_sentence, return_tensors = \"pt\").cuda()\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad04e2ce-ccb3-46a1-a722-86d5505a8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0, 250099,      1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\OneDrive\\Desktop\\fyp\\fypEnv\\Lib\\site-packages\\transformers\\generation\\utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_out = model.generate(token_ids)\n",
    "print(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdcb6e2-5f9b-448a-b1e1-6cd768562d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[1042, 3889,  669, 1494,  339, 1627,  259,  262, 2978,  259,  272, 1982,\n",
      "         1315,  260,    1]])\n",
      "Tokens: ['▁<', 'jp', '>', '▁This', '▁is', '▁just', '▁', 'a', '▁test', '▁', 'n', 'bu', 'ig', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "example_input_str = '<jp> This is just a test nbuig.'\n",
    "# example_input_str = 'これは普通のテスト'\n",
    "input_ids = tokenizer.encode(example_input_str, return_tensors='pt')\n",
    "print('Input IDs:', input_ids)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print('Tokens:', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75dedbfc-e963-4233-8be3-14e504525206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(tokenizer.vocab.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a563b2-d819-40b0-aa03-b7b43f5788b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"odunola/spanish-english-pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65995e54-5e5d-463a-ad4b-86a83f204e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9e2a90a-2c5f-49d9-9893-2b7b0f650844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['english', 'spanish'],\n",
       "        num_rows: 139013\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85459e0a-585b-4770-9181-2f7329c16c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/odunola/spanish-english-pairs/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b0e906-5f82-493f-86cf-cad9718cae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139013 entries, 0 to 139012\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   english  139013 non-null  object\n",
      " 1   spanish  139013 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc24c1a3-5cf8-4b7f-be9d-c4409cfea7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       Go.\n",
       "1                                                       Go.\n",
       "2                                                       Go.\n",
       "3                                                       Go.\n",
       "4                                                       Hi.\n",
       "                                ...                        \n",
       "139008    A carbon footprint is the amount of carbon dio...\n",
       "139009    Since there are usually multiple websites on a...\n",
       "139010    If you want to sound like a native speaker, yo...\n",
       "139011    It may be impossible to get a completely error...\n",
       "139012    One day, I woke up to find that God had put ha...\n",
       "Name: english, Length: 139013, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583718b1-87d1-4f85-9a74-dcf1a02c8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee29b2e2-7070-4213-887b-c5bec7bfa0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"english\"], df[\"spanish\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c78f959-75eb-4664-82ad-a38258a81cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91785                    She's concerned about your safety.\n",
       "63860                          I'll be there rain or shine.\n",
       "137495    There are usually never many cars on the road ...\n",
       "132868    Tom's French improved after he started studyin...\n",
       "114924           It's getting harder for me to concentrate.\n",
       "                                ...                        \n",
       "110268             No matter where you go, I'll follow you.\n",
       "119879         You can see the setting sun from the window.\n",
       "103694               He does not have any relatives at all.\n",
       "131932    Is there something in particular that you want...\n",
       "121958       His aunt takes care of his dog during the day.\n",
       "Name: english, Length: 111210, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac746d8f-ce26-4d1b-8a57-e09b7754ab25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypEnvJupyter",
   "language": "python",
   "name": "fypenvjupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
